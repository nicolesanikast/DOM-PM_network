#diameter(g.data.nom.type.binary)
n.nodes <- vcount(g.data.nom.type.binary)
n.links  <- ecount(g.data.nom.type.binary)
p.degree <- ecount(g.data.nom.type.binary)/(sum(V(g.data.nom.type.binary)$type) * sum(V(g.data.nom.type.binary)$type == FALSE))#the probability of linking in a G(n,p) model that corresponds to
#the empirical network. is adjusted to a bipartite network, since the average number of linksin for the nom is |ENP|*p which is also ecount(nom)/|nom| which is
#p = ecount(nom)/(|nom|*|enp|) => ecount(network)/(|NOM|*|ENP|)
g.mean.degree <- 2*ecount(g.data.nom.type.binary)/vcount(g.data.nom.type.binary)#mean degree:
g.assor  <- assortativity_degree(g.data.nom.type.binary,directed = FALSE)
#is the graph sparse?
g.rho <- ecount(g.data.nom.type.binary)/(sum(V(g.data.nom.type.binary)$type) * sum(V(g.data.nom.type.binary)$type == FALSE))
g.diameter <- diameter(g.data.nom.type.binary)
g.path <- average.path.length(g.data.nom.type.binary)
#
random.values <- sapply(1:n.random,function(x) {
set.seed(x)#set seed number for reproducibility
g.data.nom.type.rand <- bipartite.random.game(sum(V(g.data.nom.type)$type == TRUE), sum(V(g.data.nom.type)$type != TRUE), type  = "gnp", p = p.degree)
n.nodes <- vcount(g.data.nom.type.rand)
n.links <- ecount(g.data.nom.type.rand)
dim  <-  diameter(g.data.nom.type.rand)
av.path  <-  average.path.length(g.data.nom.type.rand)
deg.assor  <-  assortativity_degree(g.data.nom.type.rand)
dens  <- n.links/(sum(V(g.data.nom.type.rand)$type)*sum(V(g.data.nom.type.rand)$type == FALSE))
mean.degree <- 2*n.links/n.nodes
return(data.frame(dim,av.path, deg.assor, dens, mean.degree, n.nodes, n.links))})
random.values  <- data.frame(t(apply(random.values, 2, unlist)))
#Calculate the empirical quantiles of each parameter (95\% two sides confidence interval will be the range of values between the 2.5% and 97.5% empirical quantiles)
random.values.95  <- data.frame(sapply(1:ncol(random.values), function(x) return(list(quantile(random.values[ ,x], probs = 0.025),
quantile(random.values[ ,x], probs = 0.975)))))
colnames(random.values.95)  <- names(random.values)#give meaningful names to each column
#if the observed parameter is strictly less than 2.5% quantile of strictly more than the 97.5% quantile the value is outside of the 95% confidence interval -> significant
if(g.diameter < as.numeric(random.values.95$dim[1]) || g.diameter > as.numeric(random.values.95$dim[2])){diam.sig <- "*"}else{diam.sig<- as.character()}
if(g.path < as.numeric(random.values.95$av.path[1]) || g.path > as.numeric(random.values.95$av.path[2])){path.sig <- "*"}else{path.sig<- as.character()}
if(g.rho < as.numeric(random.values.95$dens[1]) || g.rho > as.numeric(random.values.95$dens[2])){dens.sig <- "*"}else{dens.sig<- as.character()}
if(g.assor < as.numeric(random.values.95$deg.assor[1]) || g.assor > as.numeric(random.values.95$deg.assor[2])){assor.sig <- "*"}else{assor.sig <- as.character()}
if(g.mean.degree < as.numeric(random.values.95$mean.degree[1]) || g.mean.degree > as.numeric(random.values.95$mean.degree[2])){mean.deg.sig <- "*"}else{mean.deg.sig <- as.character()}
#Ensemble the summery table for the properties:
prop.summary.table <- data.frame("Parameter" = c("mean degree","diameter","average shortest path","density","degree assortativity"),
"Empirical network" = c(paste(signif(g.mean.degree,digits = 2),mean.deg.sig),paste(signif(g.diameter,digits = 2),diam.sig),paste(signif(g.path,digits = 2),path.sig),paste(signif(g.rho,digits = 2),dens.sig),paste(signif(g.assor,digits = 2),assor.sig)),
"Random network" = c(paste("[",as.character(signif(as.numeric(random.values.95$mean.degree[1]),digits = 2)),",",as.character(signif(as.numeric(random.values.95$mean.degree[2]),digits = 2)),"]",sep = ""),paste("[",as.character(signif(as.numeric(random.values.95$dim[1]),digits = 2)),",",as.character(signif(as.numeric(random.values.95$dim[2]),digits = 2)),"]",sep = ""),
paste("[",as.character(signif(as.numeric(random.values.95$av.path[1]),digits = 2)),",",as.character(signif(as.numeric(random.values.95$av.path[2]),digits = 2)),"]",sep = ""),
paste("[",as.character(signif(as.numeric(random.values.95$dens[1]),digits = 2)),",",as.character(signif(as.numeric(random.values.95$dens[2]),digits = 2)),"]",sep = ""),
paste("[",as.character(signif(as.numeric(random.values.95$deg.assor[1]),digits = 2)),",",as.character(signif(as.numeric(random.values.95$deg.assor[2]),digits = 2)),"]",sep = "")))
# Supporting information - Table S3 ---------------------------------------
print(
xtable(prop.summary.table,caption = "properties",label = "table:basicnetworkprop",align = "llcc",digits = rep(0,4))
,include.rownames = FALSE,caption.placement ="top",table.placement = "H",floating = TRUE,sanitize.text.function = function(x) {x}, scalebox = 0.7)
summary(d.pca.output, loadings = T)#PCA output including the variable loadings
nrow(d.data.nom.type[d.data.nom.type$year >= 2012, ])
signif(nrow(d.data.nom.type[d.data.nom.type$year >= 2012, ])/nrow(d.data.nom.type), digits = 2)#the fraction of experiments in the last period
save.image("~/Downloads/workspace_171216.RData")
inter.type.dist.yrand <- c()
intra.type.dist.yrand <- c()
d.pca.summary.yran <- d.pca.summary
for(y in 1:1000){
d.pca.summary.yran$type <- d.pca.summary.yran$type[sample(1:nrow(d.pca.summary.yran), replace = F)]#randomize the labels of the humic substances
for(i in 1:(nrow(dist.matrix)-1)){#distances should not be recalculates only the seperation of same label vs. different label
current.type <- as.character(d.pca.summary.yran$type[i])
for(j in (i+1):nrow(dist.matrix)){#going over only the upper half of the matrix without the diagonal
if(as.character(d.pca.summary.yran$type[j]) == current.type){
intra.type.dist.yrand <- c(intra.type.dist.yrand, dist.matrix[i, j])
}else{inter.type.dist.yrand <- c(inter.type.dist.yrand, dist.matrix[i, j])}
}
}
}
inter.type.dist.yrand <- c()
intra.type.dist.yrand <- c()
d.pca.summary.yran <- d.pca.summary
for(y in 1:1000){
d.pca.summary.yran$type <- d.pca.summary.yran$type[sample(1:nrow(d.pca.summary.yran), replace = F)]#randomize the labels of the humic substances
for(i in 1:(nrow(dist.matrix)-1)){#distances should not be recalculates only the seperation of same label vs. different label
current.type <- as.character(d.pca.summary.yran$type[i])
for(j in (i+1):nrow(dist.matrix)){#going over only the upper half of the matrix without the diagonal
if(as.character(d.pca.summary.yran$type[j]) == current.type){
intra.type.dist.yrand <- c(intra.type.dist.yrand, dist.matrix[i, j])
}else{inter.type.dist.yrand <- c(inter.type.dist.yrand, dist.matrix[i, j])}
}
}
}
d.data.pca
d.pca.red
plot(d.pca.red$Aliphatic.0..110ppm.)
hist(d.pca.red$Aliphatic.0..110ppm.)
hist(d.pca.red$Aroamtic.110..165.)
hist(d.pca.red$Carbonyl.165..220.)
log(hist(d.pca.red$Carbonyl.165..220.))
hist(log(d.pca.red$Carbonyl.165..220.))
hist(log(d.pca.red$Aroamtic.110..165.))
d.pca.output  <- princomp(d.pca.red[ ,c("Aliphatic.0..110ppm.", "Aroamtic.110..165.", "Carbonyl.165..220."
)], cor =T, covmat = " cov.mcd")#perform PCA on the scaled data
d.pca.output  <- princomp(d.pca.red[ ,c("Aliphatic.0..110ppm.", "Aroamtic.110..165.", "Carbonyl.165..220."
)], cor =T, covmat = "cov.mcd")#perform PCA on the scaled data
d.pca.output  <- princomp(d.pca.red[ ,c("Aliphatic.0..110ppm.", "Aroamtic.110..165.", "Carbonyl.165..220."
)], cor =T, covmat = cov.mcd)#perform PCA on the scaled data
library(MASS)
d.pca.output  <- princomp(d.pca.red[ ,c("Aliphatic.0..110ppm.", "Aroamtic.110..165.", "Carbonyl.165..220."
)], cor =T, covmat = cov.mcd(d.pca.red[ ,c("Aliphatic.0..110ppm.", "Aroamtic.110..165.", "Carbonyl.165..220."
)]))#perform PCA on the scaled data
d.pca.output  <- princomp(d.pca.red[ ,c("Aliphatic.0..110ppm.", "Aroamtic.110..165.", "Carbonyl.165..220."
)], cor =T, covmat = cov.rob(d.pca.red[ ,c("Aliphatic.0..110ppm.", "Aroamtic.110..165.", "Carbonyl.165..220."
)]))#perform PCA on the scaled data
summary(d.pca.output, loadings = T)#PCA output including the variable loadings
d.pca.summary <- data.frame(PC1 = jitter(d.pca.output$scores[, 1]), PC2 = d.pca.output$score[, 2], type = d.pca.red$TYPE,
color = d.pca.red$col, source = d.pca.red$SOURCE)#summary data frame
upper.left <- which(d.pca.summary$PC1 <0 & d.pca.summary$PC2 >0)
length(upper.left)#number of matrials in this quadrant
#what is the most prevelnt material in this quadrant?
top.source.upper.left <- percentage.in.quadrant(d.pca.summary, upper.left)
#all the materials that fall in the lower left region, exclusing those fall directly on the horizontal and vertical lines:
lower.left <- which(d.pca.summary$PC1 <0 & d.pca.summary$PC2 <0)
length(lower.left)#number of matrials in this quadrant
top.source.lower.left <- percentage.in.quadrant(d.pca.summary, lower.left)
#all the materials that fall in the lower right region, exclusing those fall directly on the horizontal and vertical lines:
lower.right <- which(d.pca.summary$PC1 >0 & d.pca.summary$PC2 <0)
length(lower.right)#number of matrials in this quadrant
top.source.lower.right <- percentage.in.quadrant(d.pca.summary, lower.right)
#all the materials that fall in the upper left region, exclusing those fall directly on the horizontal and vertical lines:
upper.right <- which(d.pca.summary$PC1 >0 & d.pca.summary$PC2 >0)
length(upper.right)#number of matrials in this quadrant
top.source.upper.right <- percentage.in.quadrant(d.pca.summary, upper.right)
#list of all these regions:
regions <- list(upper.left, lower.left, lower.right, upper.right)
#obtain the mean and std of the carbonyl distributiono of each region
hist.data <- data.frame()
for(i in 1:length(regions)){
t <- d.pca.red[regions[[i]], c("Aliphatic.0..110ppm.", "Aroamtic.110..165.", "Carbonyl.165..220.")]
t <- melt(t)
t$panel <- i
hist.data <- rbind(hist.data, t)
}
hist.data$panel <- factor(hist.data$panel, levels = c(1,4,2,3))#reorder the panels
#density plots:
ggplot(data = hist.data, aes(x = value, fill = variable)) +
geom_density(alpha = 0.7) +
facet_wrap(~panel) +
#facet_wrap(~panel, scales='free_y') + #to have each panel have it's own y scale
theme_classic(base_size = 7) +
theme(axis.line.x = element_line(color="black", size = 0.1),
#axis.line.y = element_line(color="black", size = 0.1),
#axis.ticks = element_blank(),
#axis.text = element_blank(),
#axis.title = element_blank(),
axis.text = element_text(size = 12),
axis.title = element_text(size = 14),
strip.background = element_blank(),
legend.text = element_text(size  = 12),
legend.title = element_text(size = 14),
legend.position = "top",
#legend.direction = "vertical",
strip.text.x = element_blank()) +
annotate("text", label = c("PC1 < 0, PC2 > 0","PC1 > 0, PC2 > 0", "PC1 < 0, PC2 < 0", "PC1 > 0, PC2 < 0"), x =50, y = 0.15, size = 5, fontface =2) +
annotate("text", label = c(top.source.upper.left, top.source.upper.right, top.source.lower.left, top.source.lower.right), x =50, y = 0.10, size = 4.5) +
annotate("text", label = c(paste(as.character(length(upper.left)), "samples", sep =  " "),
paste(as.character(length(upper.right)), "samples", sep =  " "),
paste(as.character(length(lower.left)), "samples", sep =  " "),
paste(as.character(length(lower.right)), "samples", sep =  " ")), x =50, y = 0.07, size = 3.5) +
annotate("text", label = c("a","b", "c", "d"), x =0, y = 0.15, size = 5, fontface =2) +
scale_fill_discrete(guide = guide_legend(ncol =  1, title = "carbon type"), labels = c("aliphatic", "aromatic", "carbonyl")) +
labs(x = "% Carbon", y = "Probability")
ggplot(d.pca.summary) +
geom_vline(xintercept = 0, size = 0.1) +
geom_hline(yintercept = 0, size = 0.1) +
geom_point(aes(PC1, PC2, color = type), size = 3)+#, color = 'grey') +
geom_label_repel(force = 10,
aes(PC1, PC2, fill = type, label = source),
fontface = 'bold', color = 'white',
label.size = 1.5,
size = 2,
box.padding = unit(0.25, "lines"),
point.padding = unit(0.5, "lines")
) +
scale_fill_discrete(guide = guide_legend(ncol =  1, title = "NOM source")) +
scale_color_discrete(guide = F) +#omit the redundant point legend
#geom_text(aes(d.pca.summary[, 1], d.pca.summary[, 2], label = ""), show.legend  = F) +
theme_classic(base_size = 7) +
theme(axis.line.x = element_line(color="black", size = 0.1),
axis.text = element_text(size = 12),
axis.title = element_text(size = 14),
legend.title = element_text(size = 14),
legend.text = element_text(size = 8),
axis.line.y = element_line(color="black", size = 0.1))
d.pca.output  <- princomp(d.pca.red[ ,c("Aliphatic.0..110ppm.", "Aroamtic.110..165.", "Carbonyl.165..220."
)], cor =T)#perform PCA on the scaled data
d.pca.output  <- princomp(d.pca.red[ ,c("Aliphatic.0..110ppm.", "Aroamtic.110..165.", "Carbonyl.165..220."
)], cor =T, covmat = cov.rob(d.pca.red[ ,c("Aliphatic.0..110ppm.", "Aroamtic.110..165.", "Carbonyl.165..220."
)]))#perform PCA on the scaled data
summary(d.pca.output, loadings = T)#PCA output including the variable loadings
d.pca.summary <- data.frame(PC1 = jitter(d.pca.output$scores[, 1]), PC2 = d.pca.output$score[, 2], type = d.pca.red$TYPE,
color = d.pca.red$col, source = d.pca.red$SOURCE)#summary data frame
upper.left <- which(d.pca.summary$PC1 <0 & d.pca.summary$PC2 >0)
length(upper.left)#number of matrials in this quadrant
#what is the most prevelnt material in this quadrant?
top.source.upper.left <- percentage.in.quadrant(d.pca.summary, upper.left)
#all the materials that fall in the lower left region, exclusing those fall directly on the horizontal and vertical lines:
lower.left <- which(d.pca.summary$PC1 <0 & d.pca.summary$PC2 <0)
length(lower.left)#number of matrials in this quadrant
top.source.lower.left <- percentage.in.quadrant(d.pca.summary, lower.left)
#all the materials that fall in the lower right region, exclusing those fall directly on the horizontal and vertical lines:
lower.right <- which(d.pca.summary$PC1 >0 & d.pca.summary$PC2 <0)
length(lower.right)#number of matrials in this quadrant
top.source.lower.right <- percentage.in.quadrant(d.pca.summary, lower.right)
#all the materials that fall in the upper left region, exclusing those fall directly on the horizontal and vertical lines:
upper.right <- which(d.pca.summary$PC1 >0 & d.pca.summary$PC2 >0)
length(upper.right)#number of matrials in this quadrant
top.source.upper.right <- percentage.in.quadrant(d.pca.summary, upper.right)
#list of all these regions:
regions <- list(upper.left, lower.left, lower.right, upper.right)
#obtain the mean and std of the carbonyl distributiono of each region
hist.data <- data.frame()
for(i in 1:length(regions)){
t <- d.pca.red[regions[[i]], c("Aliphatic.0..110ppm.", "Aroamtic.110..165.", "Carbonyl.165..220.")]
t <- melt(t)
t$panel <- i
hist.data <- rbind(hist.data, t)
}
hist.data$panel <- factor(hist.data$panel, levels = c(1,4,2,3))#reorder the panels
#density plots:
ggplot(data = hist.data, aes(x = value, fill = variable)) +
geom_density(alpha = 0.7) +
facet_wrap(~panel) +
#facet_wrap(~panel, scales='free_y') + #to have each panel have it's own y scale
theme_classic(base_size = 7) +
theme(axis.line.x = element_line(color="black", size = 0.1),
#axis.line.y = element_line(color="black", size = 0.1),
#axis.ticks = element_blank(),
#axis.text = element_blank(),
#axis.title = element_blank(),
axis.text = element_text(size = 12),
axis.title = element_text(size = 14),
strip.background = element_blank(),
legend.text = element_text(size  = 12),
legend.title = element_text(size = 14),
legend.position = "top",
#legend.direction = "vertical",
strip.text.x = element_blank()) +
annotate("text", label = c("PC1 < 0, PC2 > 0","PC1 > 0, PC2 > 0", "PC1 < 0, PC2 < 0", "PC1 > 0, PC2 < 0"), x =50, y = 0.15, size = 5, fontface =2) +
annotate("text", label = c(top.source.upper.left, top.source.upper.right, top.source.lower.left, top.source.lower.right), x =50, y = 0.10, size = 4.5) +
annotate("text", label = c(paste(as.character(length(upper.left)), "samples", sep =  " "),
paste(as.character(length(upper.right)), "samples", sep =  " "),
paste(as.character(length(lower.left)), "samples", sep =  " "),
paste(as.character(length(lower.right)), "samples", sep =  " ")), x =50, y = 0.07, size = 3.5) +
annotate("text", label = c("a","b", "c", "d"), x =0, y = 0.15, size = 5, fontface =2) +
scale_fill_discrete(guide = guide_legend(ncol =  1, title = "carbon type"), labels = c("aliphatic", "aromatic", "carbonyl")) +
labs(x = "% Carbon", y = "Probability")
d.pca.output  <- princomp(d.pca.red[ ,c("Aliphatic.0..110ppm.", "Aroamtic.110..165.", "Carbonyl.165..220."
)], cor =T)#perform PCA on the scaled data
summary(d.pca.output, loadings = T)#PCA output including the variable loadings
d.pca.summary <- data.frame(PC1 = jitter(d.pca.output$scores[, 1]), PC2 = d.pca.output$score[, 2], type = d.pca.red$TYPE,
color = d.pca.red$col, source = d.pca.red$SOURCE)#summary data frame
# Figure 1 - carbon content distribution in PC dimensions ---------------
#Figure iterpertation of the pca results:
#It depicts the representative percentages of the different carbon content for the materials that fall within each quarter
#of the PC1-PC2 space. It excludes the material that lay exactly on the horizontal and vertical lines
#all the materials that fall in the upper left region, exclusing those fall directly on the horizontal and vertical lines:
upper.left <- which(d.pca.summary$PC1 <0 & d.pca.summary$PC2 >0)
length(upper.left)#number of matrials in this quadrant
#what is the most prevelnt material in this quadrant?
top.source.upper.left <- percentage.in.quadrant(d.pca.summary, upper.left)
#all the materials that fall in the lower left region, exclusing those fall directly on the horizontal and vertical lines:
lower.left <- which(d.pca.summary$PC1 <0 & d.pca.summary$PC2 <0)
length(lower.left)#number of matrials in this quadrant
top.source.lower.left <- percentage.in.quadrant(d.pca.summary, lower.left)
#all the materials that fall in the lower right region, exclusing those fall directly on the horizontal and vertical lines:
lower.right <- which(d.pca.summary$PC1 >0 & d.pca.summary$PC2 <0)
length(lower.right)#number of matrials in this quadrant
top.source.lower.right <- percentage.in.quadrant(d.pca.summary, lower.right)
#all the materials that fall in the upper left region, exclusing those fall directly on the horizontal and vertical lines:
upper.right <- which(d.pca.summary$PC1 >0 & d.pca.summary$PC2 >0)
length(upper.right)#number of matrials in this quadrant
top.source.upper.right <- percentage.in.quadrant(d.pca.summary, upper.right)
#list of all these regions:
regions <- list(upper.left, lower.left, lower.right, upper.right)
#obtain the mean and std of the carbonyl distributiono of each region
hist.data <- data.frame()
for(i in 1:length(regions)){
t <- d.pca.red[regions[[i]], c("Aliphatic.0..110ppm.", "Aroamtic.110..165.", "Carbonyl.165..220.")]
t <- melt(t)
t$panel <- i
hist.data <- rbind(hist.data, t)
}
hist.data$panel <- factor(hist.data$panel, levels = c(1,4,2,3))#reorder the panels
#density plots:
ggplot(data = hist.data, aes(x = value, fill = variable)) +
geom_density(alpha = 0.7) +
facet_wrap(~panel) +
#facet_wrap(~panel, scales='free_y') + #to have each panel have it's own y scale
theme_classic(base_size = 7) +
theme(axis.line.x = element_line(color="black", size = 0.1),
#axis.line.y = element_line(color="black", size = 0.1),
#axis.ticks = element_blank(),
#axis.text = element_blank(),
#axis.title = element_blank(),
axis.text = element_text(size = 12),
axis.title = element_text(size = 14),
strip.background = element_blank(),
legend.text = element_text(size  = 12),
legend.title = element_text(size = 14),
legend.position = "top",
#legend.direction = "vertical",
strip.text.x = element_blank()) +
annotate("text", label = c("PC1 < 0, PC2 > 0","PC1 > 0, PC2 > 0", "PC1 < 0, PC2 < 0", "PC1 > 0, PC2 < 0"), x =50, y = 0.15, size = 5, fontface =2) +
annotate("text", label = c(top.source.upper.left, top.source.upper.right, top.source.lower.left, top.source.lower.right), x =50, y = 0.10, size = 4.5) +
annotate("text", label = c(paste(as.character(length(upper.left)), "samples", sep =  " "),
paste(as.character(length(upper.right)), "samples", sep =  " "),
paste(as.character(length(lower.left)), "samples", sep =  " "),
paste(as.character(length(lower.right)), "samples", sep =  " ")), x =50, y = 0.07, size = 3.5) +
annotate("text", label = c("a","b", "c", "d"), x =0, y = 0.15, size = 5, fontface =2) +
scale_fill_discrete(guide = guide_legend(ncol =  1, title = "carbon type"), labels = c("aliphatic", "aromatic", "carbonyl")) +
labs(x = "% Carbon", y = "Probability")
nrow(d.pca.red)#number of humic substances in this analysis
d.dom.avail <- read.csv("../newdata/dom_propr_avail.csv", header = T)
head(d.dom.avail)
colnames(d.dom.avail)
d.dom.avail <- d.dom.avail[, c("X", "IHSS.", "suva", "Mw", "elemental.comp", "X13C.NMR..full.spectra.")]
#remove empty rows
d.dom.avail <- d.dom.avail[!d.dom.avail$X == "", ]
d.dom.avail <- d.dom.avail[order(d.dom.avail$IHSS), ]
d.dom.avail$X <- tolower(endofline.remover(d.dom.avail$X)) #replace NA with zeros)
100*nrow(d.dom.avail[complete.cases(d.dom.avail),])/nrow(d.dom.avail)#how many complete cases are there? in percent
100*sum(!is.na(d.dom.avail$Mw))/nrow(d.dom.avail)#how many MW is reported?
100*sum(!is.na(d.dom.avail$suva))/nrow(d.dom.avail)#how many MW is reported?
100*sum(!is.na(d.dom.avail$elemental.comp))/nrow(d.dom.avail)#how many MW is reported?
100*sum(!is.na(d.dom.avail$X13C.NMR..full.spectra.))/nrow(d.dom.avail)#how many MW is reported?
#sanity check:  are there names mismatches between the databases? besides unspecific fulvic and humic acids are not considered
unique(tolower(d.data.nom.type$NOM.by.location)[d.data.nom.type$NOM.type%in%group1.dom][!tolower(d.data.nom.type$NOM.by.location[d.data.nom.type$NOM.type%in%group1.dom])%in%d.dom.avail$X])
d.dom.avail$X[!d.dom.avail$X%in%tolower(d.data.nom.type$NOM.by.location[d.data.nom.type$NOM.type%in%group1.dom])]#one entry is not found
d.dom.avail.nona <- data.frame(apply(d.dom.avail[, c("suva", "Mw", "elemental.comp", "X13C.NMR..full.spectra.")], 2, na.zero)) #replace NA with zeros)
#d.dom.avail.nona <- d.dom.avail.nona[, c("suva", "Mw", "elemental.comp", "X13C.NMR..full.spectra.")]
rownames(d.dom.avail.nona) <- rownames(d.dom.avail$X)
d.dom.avail.nona$suva <- as.numeric(as.character(d.dom.avail.nona$suva))
d.dom.avail.nona$elemental.comp <- as.numeric(as.character(d.dom.avail.nona$elemental.comp))
d.dom.avail.nona$Mw <- as.numeric(as.character(d.dom.avail.nona$Mw))
d.dom.avail.nona$X13C.NMR..full.spectra. <- as.numeric(as.character(d.dom.avail.nona$X13C.NMR..full.spectra.))
str(d.dom.avail)
length(unique(as.character(d.data.nom.type$Full.paper.title[d.data.nom.type$NOM.type%in%group1.dom])))
#no molecular weight
length(unique(as.character(d.data.nom.type$Full.paper.title[tolower(d.data.nom.type$NOM.by.location)%in%as.character(d.dom.avail$X[d.dom.avail.nona$Mw == 0])])))
#no suva
length(unique(as.character(d.data.nom.type$Full.paper.title[tolower(d.data.nom.type$NOM.by.location)%in%as.character(d.dom.avail$X[d.dom.avail.nona$suva == 0])])))
#no elemental composition
length(unique(as.character(d.data.nom.type$Full.paper.title[tolower(d.data.nom.type$NOM.by.location)%in%as.character(d.dom.avail$X[d.dom.avail.nona$X13C.NMR..full.spectra. == 0])])))
length(unique(as.character(d.data.nom.type$Full.paper.title[tolower(d.data.nom.type$NOM.by.location)%in%as.character(d.dom.avail$X[d.dom.avail.nona$elemental.comp == 0])])))
#number of papers that use group1 DOM for which MW, elemental composition or nmr spectra are unknown:
length(unique(as.character(d.data.nom.type$Full.paper.title[
d.data.nom.type$NOM.by.location%in%as.character(d.dom.avail$X[d.dom.avail.nona$Mw == 0 &
d.dom.avail.nona$elemental.comp == 0 & d.dom.avail.nona$X13C.NMR..full.spectra. == 0])])))
#number of publications which use at least 1 grouo1-DOM for which all parameters are known:
length(unique(as.character(c(d.data.nom.type$Full.paper.title[tolower(d.data.nom.type$NOM.by.location)%in%as.character(d.dom.avail$X[d.dom.avail.nona$Mw == 1])],
d.data.nom.type$Full.paper.title[tolower(d.data.nom.type$NOM.by.location)%in%as.character(d.dom.avail$X[d.dom.avail.nona$X13C.NMR..full.spectra. == 1])],
d.data.nom.type$Full.paper.title[tolower(d.data.nom.type$NOM.by.location)%in%as.character(d.dom.avail$X[d.dom.avail.nona$elemental.comp == 1])]))))
length(unique(as.character(d.data.nom.type$Full.paper.title[tolower(d.data.nom.type$NOM.by.location)%in%as.character(d.dom.avail$X[d.dom.avail.nona$Mw == 1]) |
tolower(d.data.nom.type$NOM.by.location)%in%as.character(d.dom.avail$X[d.dom.avail.nona$X13C.NMR..full.spectra. == 1]) |
tolower(d.data.nom.type$NOM.by.location)%in%as.character(d.dom.avail$X[d.dom.avail.nona$elemental.comp == 1])])))
#number of publications which use at least 1 group1-DOM for which at least 1 value is unknown: (they can use multiple DOM for which the a value is known)
length(unique(as.character(c(d.data.nom.type$Full.paper.title[tolower(d.data.nom.type$NOM.by.location)%in%as.character(d.dom.avail$X[d.dom.avail.nona$Mw == 0])],
d.data.nom.type$Full.paper.title[tolower(d.data.nom.type$NOM.by.location)%in%as.character(d.dom.avail$X[d.dom.avail.nona$X13C.NMR..full.spectra. == 0])],
d.data.nom.type$Full.paper.title[tolower(d.data.nom.type$NOM.by.location)%in%as.character(d.dom.avail$X[d.dom.avail.nona$elemental.comp == 0])]))))
length(unique(as.character(d.data.nom.type$Full.paper.title[d.data.nom.type$NOM.by.location%in%as.character(d.dom.avail$X[d.dom.avail.nona$Mw == 0]) &
d.data.nom.type$NOM.by.location%in%as.character(d.dom.avail$X[d.dom.avail.nona$suva == 0])])))
length(unique(as.character(d.data.nom.type$Full.paper.title[d.data.nom.type$NOM.by.location%in%as.character(d.dom.avail$X[d.dom.avail.nona$suva == 0])])))
#number of experiments that use DOM with full categorization available:
length(as.character(d.data.nom.type$Full.paper.title[d.data.nom.type$NOM.type%in%group1.dom]))
nrow(d.data.nom.type[tolower(d.data.nom.type$NOM.by.location)%in%as.character(d.dom.avail$X[d.dom.avail.nona$Mw == 1]), ])
nrow(d.data.nom.type[tolower(d.data.nom.type$NOM.by.location)%in%as.character(d.dom.avail$X[d.dom.avail.nona$Mw == 0]), ])
nrow(d.data.nom.type[tolower(d.data.nom.type$NOM.by.location)%in%as.character(d.dom.avail$X[d.dom.avail.nona$suva == 1]), ])
nrow(d.data.nom.type[tolower(d.data.nom.type$NOM.by.location)%in%as.character(d.dom.avail$X[d.dom.avail.nona$suva == 0]), ])
nrow(d.data.nom.type[d.data.nom.type$NOM.by.location%in%as.character(d.dom.avail$X[d.dom.avail.nona$Mw == 0 & d.dom.avail.nona$suva == 0]), ])
nrow(d.data.nom.type[d.data.nom.type$NOM.by.location%in%as.character(d.dom.avail$X[d.dom.avail.nona$elemental.comp == 1]), ])
nrow(d.data.nom.type[d.data.nom.type$NOM.by.location%in%as.character(d.dom.avail$X[d.dom.avail.nona$elemental.comp == 0]), ])
nrow(d.data.nom.type[tolower(d.data.nom.type$NOM.by.location)%in%as.character(d.dom.avail$X[d.dom.avail.nona$X13C.NMR..full.spectra. == 1]), ])
nrow(d.data.nom.type[tolower(d.data.nom.type$NOM.by.location)%in%as.character(d.dom.avail$X[d.dom.avail.nona$X13C.NMR..full.spectra. == 0]), ])
heatmap.data.prop <- matrix(nrow = 1, ncol = 3)
for(i in 1:nrow(d.dom.avail.nona)){
heatmap.data.prop <- rbind(heatmap.data.prop, t(rbind(rep(as.character(d.dom.avail$X[i]), 4), names(d.dom.avail.nona[i,]) ,as.numeric(d.dom.avail.nona[i,]))))
}
d.data.compat <- matrix(nrow = 1, ncol = 3)
for(i in unique(d.data.nom.type$DOI[!d.data.nom.type$DOI == ""])){
#go over all publications in the database,
used.dom <- d.data.nom.type[
d.data.nom.type$Full.paper.title == d.data.nom.type$Full.paper.title[d.data.nom.type$DOI == i], c("NOM.by.location", "NOM.type")]#all the dom of this publications
used.dom.group1 <- tolower(unique(as.character(used.dom$NOM.by.location[used.dom$NOM.type%in%group1.dom])))#the used dom names of group1
used.dom.group1 <- used.dom.group1[!used.dom.group1%in%c("unfa", "unha")]
dom.len <- length(used.dom.group1)#the number of froup-1 DOM used in this publication
if(dom.len > 1){#if there is more than 1 DOM from group 1 studied by this publication, the continue
info.array <- c()
if(sum(d.dom.avail.nona$Mw[d.dom.avail$X%in%used.dom.group1]) < dom.len & sum(d.dom.avail.nona$Mw[d.dom.avail$X%in%used.dom.group1]) > 0){#is there mixed information about their mw?
info.array <- c(info.array, 1)#mixed information
}
else if(sum(d.dom.avail.nona$Mw[d.dom.avail$X%in%used.dom.group1]) == dom.len){
info.array <- c(info.array, 2)
}else{
info.array <- c(info.array, 0)
}#conssistently missing information
if(sum(d.dom.avail.nona$suva[d.dom.avail$X%in%used.dom.group1]) < dom.len & sum(d.dom.avail.nona$suva[d.dom.avail$X%in%used.dom.group1]) > 0){#is there full information about their suva?
info.array <- c(info.array, 1)#mixed information
}
else if(sum(d.dom.avail.nona$suva[d.dom.avail$X%in%used.dom.group1]) == dom.len){#is there full information about their suva?
info.array <- c(info.array, 2)#conssitent and full information
}else{
info.array <- c(info.array, 0)#conssistently missing information
}
if(sum(d.dom.avail.nona$elemental.comp[d.dom.avail$X%in%used.dom.group1]) < dom.len & sum(d.dom.avail.nona$elemental.comp[d.dom.avail$X%in%used.dom.group1]) > 0){#is there full information about their suva?
info.array <- c(info.array, 1)
}
else if(sum(d.dom.avail.nona$elemental.comp[d.dom.avail$X%in%used.dom.group1]) == dom.len){#is there full information about their elemental comp?
info.array <- c(info.array, 2)#conssitent and full information
}else{
info.array <- c(info.array, 0)#conssistently missing information
}
if(sum(d.dom.avail.nona$X13C.NMR..full.spectra.[d.dom.avail$X%in%used.dom.group1]) < dom.len & sum(d.dom.avail.nona$X13C.NMR..full.spectra.[d.dom.avail$X%in%used.dom.group1]) >0){#is there full information about their suva?
info.array <- c(info.array, 1)
}
else if(sum(d.dom.avail.nona$X13C.NMR..full.spectra.[d.dom.avail$X%in%used.dom.group1]) == dom.len){#is there full information about their suva?
info.array <- c(info.array, 2)#conssitent and full information
}
else{#is there full information about their suva?
info.array <- c(info.array, 0)#conssistently missing information
}
d.data.compat <- rbind(d.data.compat, t(rbind(rep(as.character(i), 4),
c("molecular weight", "SUVA", "elmental composition", "13C NMR"), info.array)))
}
}
nrow(d.data.compat)/4
nrow(d.data.compat)
info.array
p <- (ggplot(d.data.compat, aes(publication, test)) +
geom_tile(aes(fill = full.information), colour = "white") +
scale_fill_manual(drop=FALSE, values= c("grey87", "grey50", "grey20"), na.value="#EEEEEE", name="DOM characteization",
labels = c("completely missing", "mixed", "full information")) +
theme(axis.ticks = element_blank(),
axis.text.x = element_text(size = 6, angle = -90, hjust = 0),
legend.title = element_text(colour = "grey30"),
plot.margin = unit(c(0, 0, 0, 0), "cm"),
axis.title.x=element_blank(),
axis.title.y=element_blank()
))
p
d.data.compat <- data.frame(d.data.compat)
#d.data.compat[, 3] <- d.data.compat[, 3]#conver column to numeric
d.data.compat <- d.data.compat[-1, ]#remove first NA row
colnames(d.data.compat) <- c("publication", "test", "full.information")
p <- (ggplot(d.data.compat, aes(publication, test)) +
geom_tile(aes(fill = full.information), colour = "white") +
scale_fill_manual(drop=FALSE, values= c("grey87", "grey50", "grey20"), na.value="#EEEEEE", name="DOM characteization",
labels = c("completely missing", "mixed", "full information")) +
theme(axis.ticks = element_blank(),
axis.text.x = element_text(size = 6, angle = -90, hjust = 0),
legend.title = element_text(colour = "grey30"),
plot.margin = unit(c(0, 0, 0, 0), "cm"),
axis.title.x=element_blank(),
axis.title.y=element_blank()
))
p
nrow(d.data.compat)
nrow(d.data.compat)/4
l <- length(d.data.compat$publication[d.data.compat$test == "SUVA"])#number of papers that employ at least two group-1 DOM types:
l
table(d.data.compat[d.data.compat$test == "SUVA", "full.information"])
sum(aggregate(as.numeric(as.character(d.data.compat$full.information)), by = list(d.data.compat$publication), FUN = sum) == 8)
21/271
sum(aggregate(as.numeric(as.character(d.data.compat$full.information)), by = list(d.data.compat$publication), FUN = sum) == 8)/l #the fraction of papers that have
inter.type.dist.yrand <- c()
intra.type.dist.yrand <- c()
d.pca.summary.yran <- d.pca.summary
for(y in 1:100){
d.pca.summary.yran$type <- d.pca.summary.yran$type[sample(1:nrow(d.pca.summary.yran), replace = F)]#randomize the labels of the humic substances
for(i in 1:(nrow(dist.matrix)-1)){#distances should not be recalculates only the seperation of same label vs. different label
current.type <- as.character(d.pca.summary.yran$type[i])
for(j in (i+1):nrow(dist.matrix)){#going over only the upper half of the matrix without the diagonal
if(as.character(d.pca.summary.yran$type[j]) == current.type){
intra.type.dist.yrand <- c(intra.type.dist.yrand, dist.matrix[i, j])
}else{inter.type.dist.yrand <- c(inter.type.dist.yrand, dist.matrix[i, j])}
}
}
}
pdf("FigureS8.pdf")
split.screen(m)
screen(1)
hist(inter.type.dist, xlim = range(c(intra.type.dist, inter.type.dist)),
freq = F, ylim = c(0, 1), col = "#F39C1250", border = "grey", xlab = "euclidean distance", main = "", ylab ="")
hist(intra.type.dist, add = T, xlim = range(c(intra.type.dist, inter.type.dist)), freq = F, col = "#45993C70", border = "grey")
text(x = 0.1, y = 1., label = "a", font = 2)
#screen(2)
#hist(inter.type.dist.no.soil, xlim = range(c(intra.type.dist.no.soil, inter.type.dist.no.soil)),
#    freq = F, ylim = c(0, 1), col = "#F39C1250", border = "grey", xlab = "euclidean distance", main = "", ylab = "")
#hist(intra.type.dist.no.soil, add = T, xlim = range(c(intra.type.dist.no.soil, inter.type.dist.no.soil)), freq = F, col = "#45993C70", border = "grey")
#text(x = 0.1, y = 1., label = "b", font = 2)
screen(2)
hist(inter.type.dist.yrand, xlim = range(c(intra.type.dist.yrand, inter.type.dist.yrand)),
freq = F, ylim = c(0, 1), col = "#F39C1250", border = "grey", xlab = "euclidean distance", main = "")
hist(intra.type.dist.yrand, add = T, xlim = range(c(intra.type.dist.yrand, inter.type.dist.yrand)), freq = F, col = "#45993C70", border = "grey")
text(x = 0.1, y = 1., label = "b", font = 2)
legend("topright", legend = c("different environments", "similar environments"), fill  = c("#F39C1250", "#45993C70"), cex = 0.5, border = "grey", bty = "n")
close.screen(all.screens = T)
dev.off()
sum(E(g.data.nom.type)$weight)#number of experiments (sum of links' weights)
n.comb.stud <- ecount(g.data.nom.type); n.comb.stud#number of unique DOM-PM combinations studied
467/951
d.pca.summary
d.pca.output
summary(d.pca.output, loadings =T)
load.required.packages()
nom.data.column <- "NOM.type.detailed"#DON'T comment this out! this variable is needed throughout the script
load("dataBase.Rdata")#load the R object with the database from the working directory, the data is stored in the variable "d.data.nom.type"
g.data.nom.type <- adj.to.graph(d.data.nom.type[c("ENP", nom.data.column)], d.data.nom.type$ENP)#Converting the dataset into a graph instance
V(g.data.nom.type)$degree.lables.code <- label.node.degree(g.data.nom.type)#label nodes of highest degree, DOM with letters and PM with numbers
write.graph(graph = g.data.nom.type, format = "pajek", file = "gDataNOMtype.net")
write.graph(graph = g.data.nom.type, format = "gml", file = "gDataNOMtype.gml")
write.graph(graph = g.data.nom.type, format = "Dot", file = "gDataNOMtype.dot")
write.graph(graph = g.data.nom.type, format = "Dot", file = "gDataNOMtype.dot")
write.graph(graph = g.data.nom.type, format = "Dot", file = "gDataNOMtype.dot")
write.graph(graph = g.data.nom.type, format = "dot", file = "gDataNOMtype.dot")
write.graph(graph = g.data.nom.type, format = "graphml", file = "gDataNOMtype.graphml")
